{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39152e5-69d7-4960-9069-def1ecf91331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f55303-f900-4f31-afdd-363c2ed0e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks = pd.read_csv('../data/euroleaks/cleaned.csv')\n",
    "comms = pd.read_csv('../data/communiques/cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f40f73-101f-475d-a291-bb9ad8bd1268",
   "metadata": {},
   "source": [
    "**REMARK**: in order to make sure that collocations are found separately (meaning once for document=eurpleaks and once for document=communiques), leaks and communiques are treated as two separate documents, but in order for the terms to be comparable, the collcoations are joined at the end.\n",
    "Also, some artifacts were filtered out (e.g. \"thank thank\"), and for the rest a threshold value is set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01f19e-83df-4f2b-a545-010f79e4992f",
   "metadata": {},
   "source": [
    "# Euroleaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0f8221-380b-4c05-9d54-13afe10616b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(leaks.speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b7e114-4054-4d15-b5e5-446ae0401eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load the spacy model: 0.01 mins\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "\n",
    "print(f'Time taken to load the spacy model: {round((time.time() - t) / 60, 2)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6adc56-fbc3-4061-9b97-1dfddcbce85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the spacy model: 0.4 mins\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "document = nlp(text)\n",
    "\n",
    "print(f'Time taken to run the spacy model: {round((time.time() - t) / 60, 2)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11f4e88-3581-4f65-9ec3-1a7f0daf1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import euroleaks-specific stopwords\n",
    "with open('../data/euroleaks/stopwords.json', 'r') as f:\n",
    "    stopwords = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56607289-5b59-4a85-8784-530385d1f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize, lemmatize, remove stopwords\n",
    "words = [token.lemma_.lower() for sentence in document.sents for token in sentence\n",
    "            if token.pos_ in {'ADJ', 'ADV', 'NOUN', 'PROPN', 'VERB'}\\\n",
    "            and not token.is_stop\\\n",
    "            and not token.lower_ in stopwords['names']\\\n",
    "            and not token.lower_ in stopwords['disfluency']\\\n",
    "            and not token.lower_ in stopwords['courtesy']\\\n",
    "            and len(token.lemma_)>1\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d9489-0f57-482c-873c-a7b96c771151",
   "metadata": {},
   "source": [
    "- https://www.nltk.org/howto/collocations.html\n",
    "- mi_like score: https://www.nltk.org/api/nltk.metrics.html#nltk.metrics.association.NgramAssocMeasures.mi_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f5cdd-9fc1-4c76-a346-143bae732620",
   "metadata": {},
   "source": [
    "## trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9990a37-c32d-42d6-86d8-e51a77420184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder, TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(words)\n",
    "\n",
    "# word might be highly correlated but very infrequent, ignore all with less than n occurances\n",
    "finder.apply_freq_filter(3)\n",
    "\n",
    "# not all collocations are useful: e.g. 'starting_point'\n",
    "finder.apply_word_filter(lambda w: 'valid' in w or 'thank' in w or 'lack' in w or 'particularly' in w)\n",
    "\n",
    "tgm = TrigramAssocMeasures()\n",
    "collocations = {trigram: pmi for trigram, pmi in finder.score_ngrams(tgm.mi_like)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04804f42-17ab-431d-9c02-1c6d3a65699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ddb9d87-c497-40e3-9435-a2a688a6f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('debt', 'sustainability', 'analysis'),\n",
      " ('euro', 'working', 'group'),\n",
      " ('international', 'monetary', 'fund'),\n",
      " ('low', 'interest', 'rate'),\n",
      " ('master', 'financial', 'assistance'),\n",
      " ('non', 'performing', 'loan'),\n",
      " ('sign', 'dotted', 'line'),\n",
      " ('successful', 'conclusion', 'review')]\n"
     ]
    }
   ],
   "source": [
    "leaks_trigram_colloc = sorted(finder.above_score(tgm.mi_like, 0.006))\n",
    "pprint(leaks_trigram_colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f45d1558-f8bc-4d6f-a817-b6332dee72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_trigram_colloc(s, set_colloc):\n",
    "    res = s.lower()\n",
    "    for b1,b2,b3 in set_colloc:\n",
    "        res = res.replace(f'{b1} {b2} {b3}', f'{b1}_{b2}_{b3}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23d7748f-d706-4c31-a707-45275059d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = apply_trigram_colloc(' '.join(words), leaks_trigram_colloc).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd8875a2-4922-4284-ab77-1186ffa0fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'euro_working_group' in words and 'successful_conclusion_review' in words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d8a30-182c-4794-89d0-a47c5044e553",
   "metadata": {},
   "source": [
    "## bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b344fc3-0551-4aae-956d-b38070decf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(words)\n",
    "\n",
    "# word might be highly correlated but very infrequent, ignore all with less than n occurances\n",
    "finder.apply_freq_filter(3)\n",
    "\n",
    "word_filter = [\n",
    "    'thank',\n",
    "    'start',\n",
    "    'starting',\n",
    "    'low',\n",
    "    'high',\n",
    "    'end',\n",
    "    'stand',\n",
    "    'negative',\n",
    "    'gdp',\n",
    "    'little',\n",
    "    'floor',\n",
    "    'think',\n",
    "    'staff',\n",
    "    'facility'\n",
    "]\n",
    "\n",
    "finder.apply_word_filter(lambda w: w in nlp.Defaults.stop_words or w in stopwords['names'] or w in stopwords['disfluency'] or w in stopwords['courtesy'] or w in word_filter)\n",
    "\n",
    "finder.apply_ngram_filter(lambda w1,w2: w1.endswith('ly') or w1 == 'take')\n",
    "\n",
    "bgm = BigramAssocMeasures()\n",
    "collocations = {bigram: pmi for bigram, pmi in finder.score_ngrams(bgm.mi_like)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16de3b9d-5f38-419d-8a3b-5ae1433fd3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aide', 'memoire'),\n",
      " ('anti', 'corruption'),\n",
      " ('arm', 'length'),\n",
      " ('brussels', 'group'),\n",
      " ('capital', 'control'),\n",
      " ('central', 'bank'),\n",
      " ('collective', 'bargaining'),\n",
      " ('common', 'ground'),\n",
      " ('et', 'cetera'),\n",
      " ('financial', 'stability'),\n",
      " ('govern', 'council'),\n",
      " ('greek', 'authority'),\n",
      " ('greek', 'government'),\n",
      " ('greek', 'people'),\n",
      " ('growth', 'friendly'),\n",
      " ('half', 'percent'),\n",
      " ('interest', 'rate'),\n",
      " ('labor', 'market'),\n",
      " ('maximum', 'flexibility'),\n",
      " ('member', 'state'),\n",
      " ('minimum', 'wage'),\n",
      " ('mission', 'chief'),\n",
      " ('primary', 'surplus'),\n",
      " ('prime', 'minister'),\n",
      " ('prior', 'action'),\n",
      " ('product', 'market'),\n",
      " ('quantitative', 'easing'),\n",
      " ('real', 'estate'),\n",
      " ('safety', 'net'),\n",
      " ('second', 'letter'),\n",
      " ('smp', 'bond'),\n",
      " ('structural', 'reform'),\n",
      " ('technical', 'team'),\n",
      " ('uncharted', 'territory'),\n",
      " ('united', 'states')]\n"
     ]
    }
   ],
   "source": [
    "leaks_bigram_colloc = sorted(finder.above_score(bgm.mi_like, 0.74))\n",
    "pprint(leaks_bigram_colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba944c32-df20-4218-8f2e-215ac760ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736c216-22eb-403f-8a3b-a046183aee1e",
   "metadata": {},
   "source": [
    "# Communiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "700a8109-e48c-43b7-95e7-f9ec6934e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(comms.story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfcc3339-1bf8-4ac2-ad83-ee06805356b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3297d69-340c-4960-85d7-842b8b40eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize, lemmatize, remove stopwords\n",
    "words = [token.lemma_.lower() for sentence in document.sents for token in sentence\n",
    "            if token.pos_ in {'ADJ', 'ADV', 'NOUN', 'PROPN', 'VERB'}\\\n",
    "            and not token.is_stop\\\n",
    "            and len(token.lemma_)>1\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e673d5-579f-4031-bcf9-297c22835871",
   "metadata": {},
   "source": [
    "- https://www.nltk.org/howto/collocations.html\n",
    "- mi_like score: https://www.nltk.org/api/nltk.metrics.html#nltk.metrics.association.NgramAssocMeasures.mi_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688e80c-8555-46c6-b129-20f4bb412f92",
   "metadata": {},
   "source": [
    "## trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0a95158-46f7-4ac1-95a5-a4509dbf8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder, TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(words)\n",
    "\n",
    "# word might be highly correlated but very infrequent, ignore all with less than n occurances\n",
    "finder.apply_freq_filter(3)\n",
    "\n",
    "# not all collocations are useful: e.g. 'starting_point'\n",
    "finder.apply_word_filter(lambda w: 'valid' in w or 'thank' in w)\n",
    "\n",
    "tgm = TrigramAssocMeasures()\n",
    "collocations = {trigram: pmi for trigram, pmi in finder.score_ngrams(tgm.mi_like)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35425a85-4d16-4e3e-9ded-76e2b9fb63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4bcfd95-fa8e-4e0f-9f04-17ba71f67706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('low', 'interest', 'rate'), ('successful', 'conclusion', 'review')]\n"
     ]
    }
   ],
   "source": [
    "comms_trigram_colloc = sorted(finder.above_score(tgm.mi_like, 0.125))\n",
    "pprint(comms_trigram_colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "487a027d-9634-45c8-8fb5-2e58869e13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_trigram_colloc(s, set_colloc):\n",
    "    res = s.lower()\n",
    "    for b1,b2,b3 in set_colloc:\n",
    "        res = res.replace(f'{b1} {b2} {b3}', f'{b1}_{b2}_{b3}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67870b8b-ce06-4f53-875f-cf0030e8cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = apply_trigram_colloc(' '.join(words), comms_trigram_colloc).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9c475-c138-4abb-aef5-0415125420fa",
   "metadata": {},
   "source": [
    "## bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bca245a-5274-4674-af35-9ab06667ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(words)\n",
    "\n",
    "# word might be highly correlated but very infrequent, ignore all with less than n occurances\n",
    "finder.apply_freq_filter(3)\n",
    "\n",
    "word_filter = [\n",
    "    'starting',\n",
    "    'stand',\n",
    "    'evening',\n",
    "    'mission',\n",
    "    'main',\n",
    "    'like',\n",
    "    'kind',\n",
    "    'obligation'\n",
    "]\n",
    "\n",
    "finder.apply_word_filter(lambda w: w in word_filter)\n",
    "\n",
    "finder.apply_ngram_filter(lambda w1,w2: w1.endswith('ly') or w1 == 'take')\n",
    "\n",
    "bgm = BigramAssocMeasures()\n",
    "collocations = {bigram: pmi for bigram, pmi in finder.score_ngrams(bgm.mi_like)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9c44908-1288-4774-9638-8e655b5a587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('banking', 'union'),\n",
      " ('common', 'ground'),\n",
      " ('debt', 'sustainability'),\n",
      " ('duration', 'mffa'),\n",
      " ('euro', 'area'),\n",
      " ('european', 'semester'),\n",
      " ('greek', 'authority'),\n",
      " ('greek', 'government'),\n",
      " ('member', 'states'),\n",
      " ('monetary', 'union'),\n",
      " ('national', 'procedure'),\n",
      " ('press', 'conference'),\n",
      " ('prior', 'action'),\n",
      " ('state', 'play'),\n",
      " ('structural', 'reform'),\n",
      " ('track', 'record')]\n"
     ]
    }
   ],
   "source": [
    "comms_bigram_colloc = sorted(finder.above_score(bgm.mi_like, 1.1))\n",
    "pprint(comms_bigram_colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "618cc525-7f89-47cf-b0b4-86662d6f5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea570d-3e90-4b8f-802e-80b7fec89a22",
   "metadata": {},
   "source": [
    "# Join collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a55e2647-2dbc-4d6c-92d0-cd5f73b54922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams that are in Euroleaks, but not in Communiques:\n",
      "\t ('debt', 'sustainability', 'analysis')\n",
      "\t ('euro', 'working', 'group')\n",
      "\t ('international', 'monetary', 'fund')\n",
      "\t ('master', 'financial', 'assistance')\n",
      "\t ('non', 'performing', 'loan')\n",
      "\t ('sign', 'dotted', 'line')\n",
      "\n",
      "Trigrams that are in Communiques, but not in Euroleaks:\n"
     ]
    }
   ],
   "source": [
    "print('Trigrams that are in Euroleaks, but not in Communiques:')\n",
    "for colloc in leaks_trigram_colloc:\n",
    "    if colloc not in comms_trigram_colloc:\n",
    "        print('\\t', colloc)\n",
    "        \n",
    "print('\\nTrigrams that are in Communiques, but not in Euroleaks:')\n",
    "for colloc in comms_trigram_colloc:\n",
    "    if colloc not in leaks_trigram_colloc:\n",
    "        print('\\t', colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2dd3fc45-19be-4700-917a-be06ae5a7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_colloc = set(leaks_trigram_colloc + comms_trigram_colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd3798e7-53e5-4ffd-8eb3-be5c2823f1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams that are in Euroleaks, but not in Communiques:\n",
      "\t ('aide', 'memoire')\n",
      "\t ('anti', 'corruption')\n",
      "\t ('arm', 'length')\n",
      "\t ('brussels', 'group')\n",
      "\t ('capital', 'control')\n",
      "\t ('central', 'bank')\n",
      "\t ('collective', 'bargaining')\n",
      "\t ('et', 'cetera')\n",
      "\t ('financial', 'stability')\n",
      "\t ('govern', 'council')\n",
      "\t ('greek', 'people')\n",
      "\t ('growth', 'friendly')\n",
      "\t ('half', 'percent')\n",
      "\t ('interest', 'rate')\n",
      "\t ('labor', 'market')\n",
      "\t ('maximum', 'flexibility')\n",
      "\t ('member', 'state')\n",
      "\t ('minimum', 'wage')\n",
      "\t ('mission', 'chief')\n",
      "\t ('primary', 'surplus')\n",
      "\t ('prime', 'minister')\n",
      "\t ('product', 'market')\n",
      "\t ('quantitative', 'easing')\n",
      "\t ('real', 'estate')\n",
      "\t ('safety', 'net')\n",
      "\t ('second', 'letter')\n",
      "\t ('smp', 'bond')\n",
      "\t ('technical', 'team')\n",
      "\t ('uncharted', 'territory')\n",
      "\t ('united', 'states')\n",
      "\n",
      "Bigrams that are in Communiques, but not in Euroleaks:\n",
      "\t ('banking', 'union')\n",
      "\t ('debt', 'sustainability')\n",
      "\t ('duration', 'mffa')\n",
      "\t ('euro', 'area')\n",
      "\t ('european', 'semester')\n",
      "\t ('member', 'states')\n",
      "\t ('monetary', 'union')\n",
      "\t ('national', 'procedure')\n",
      "\t ('press', 'conference')\n",
      "\t ('state', 'play')\n",
      "\t ('track', 'record')\n"
     ]
    }
   ],
   "source": [
    "print('Bigrams that are in Euroleaks, but not in Communiques:')\n",
    "for colloc in leaks_bigram_colloc:\n",
    "    if colloc not in comms_bigram_colloc:\n",
    "        print('\\t', colloc)\n",
    "        \n",
    "print('\\nBigrams that are in Communiques, but not in Euroleaks:')\n",
    "for colloc in comms_bigram_colloc:\n",
    "    if colloc not in leaks_bigram_colloc:\n",
    "        print('\\t', colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1845076-790e-4d2b-9f2e-4933d391c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_colloc = set(leaks_bigram_colloc + comms_bigram_colloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c51fe-1247-4b5e-a253-b3ecfde49c7c",
   "metadata": {},
   "source": [
    "## dump to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5feaf642-e251-4d53-ba4b-87ade0bd14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonized = json.dumps(sorted(trigram_colloc))\n",
    "with open('../data/collocations/trigrams.json', 'w') as f:\n",
    "    f.write(jsonized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56c8fa96-d96d-451a-9063-e1610b6b6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonized = json.dumps(sorted(bigram_colloc))\n",
    "with open('../data/collocations/bigrams.json', 'w') as f:\n",
    "    f.write(jsonized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e3b33-4d61-4121-b920-40d63349bb86",
   "metadata": {},
   "source": [
    "# Auxiliary data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07699eac-290e-45d1-ab6d-e5c1e0a7a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_term(term):\n",
    "    for i,row in leaks.iterrows():\n",
    "        if term in row.speech:\n",
    "            date = pd.to_datetime(row.date).strftime('%d/%m')\n",
    "            print(f'{row.speaker} ({date}):')\n",
    "            print(row.speech)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d64d8d22-a3a9-41ee-b2d3-5674e4fe66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_term('Alex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b993467-f2ca-45b4-8ad6-5e23f6435aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
