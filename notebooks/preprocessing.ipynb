{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1952f4-356b-4ace-b1a0-68aae6d74dbb",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Preprocessing needs to be done appropriately for each analysis separately. This notebook serves as a general template.\n",
    "Also, I use it to compute an approximate number of stopowords removed and tokens after preprocessing is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50ec457-a109-41de-93f2-7cd803cd110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7d181-5153-4279-b54d-b20e80ab7656",
   "metadata": {},
   "source": [
    "## Euroleaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e72e9c52-b6bb-4b30-bed1-c67065db66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/euroleaks/cleaned.csv')\n",
    "\n",
    "# stopwords\n",
    "with open('../data/euroleaks/stopwords.json', 'r') as f:\n",
    "    stopwords = json.load(f)\n",
    "    \n",
    "# collocations\n",
    "def apply_trigram_colloc(s, set_colloc):\n",
    "    res = s.lower()\n",
    "    for b1,b2,b3 in set_colloc:\n",
    "        res = res.replace(f'{b1} {b2} {b3}', f'{b1}_{b2}_{b3}')\n",
    "    return res\n",
    "\n",
    "def apply_bigram_colloc(s, set_colloc):\n",
    "    res = s.lower()\n",
    "    for b1,b2 in set_colloc:\n",
    "        res = res.replace(f'{b1} {b2}', f'{b1}_{b2}')\n",
    "    return res\n",
    "\n",
    "with open('../data/collocations/trigrams.json', 'r') as f:\n",
    "    trigram_colloc = json.load(f)\n",
    "\n",
    "with open('../data/collocations/bigrams.json', 'r') as f:\n",
    "    bigram_colloc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b36358a-a42d-4378-bd73-ad10fa415212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join speech of consecutive rows with same speaker\n",
    "\n",
    "df_squeezed = pd.DataFrame(columns=['speaker','speech','date'])\n",
    "\n",
    "previous_speaker = None\n",
    "speech = None\n",
    "previous_date = None\n",
    "\n",
    "for index, data in df.iterrows():\n",
    "    \n",
    "    if not previous_speaker and not speech and not previous_date:\n",
    "        previous_speaker = data.speaker\n",
    "        speech = data.speech\n",
    "        previous_date = data.date\n",
    "    elif data.speaker == previous_speaker and previous_date == data.date:\n",
    "        speech = ' '.join((speech, data.speech))\n",
    "    else:\n",
    "        df_squeezed.loc[len(df_squeezed.index)] = [\n",
    "            previous_speaker,\n",
    "            speech,\n",
    "            previous_date\n",
    "        ]\n",
    "        previous_speaker = data.speaker\n",
    "        speech = data.speech\n",
    "        previous_date = data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d2c5194-081a-49ea-bea1-c5e199ea46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/euroleaks/name_to_entity.json', 'r') as f:\n",
    "    speaker_to_entity = json.load(f)\n",
    "    \n",
    "# add column for entity, label unassigned as Unidentified\n",
    "df_squeezed['entity'] = df_squeezed.speaker.apply(lambda s: speaker_to_entity[s] if s in speaker_to_entity.keys() else 'Unidentified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecdb6596-3b37-4181-92e2-8180be069df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>date</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jeroen dijsselbloem</td>\n",
       "      <td>… of your responses or questions. And can I fi...</td>\n",
       "      <td>2015-02-24 00:00:00</td>\n",
       "      <td>EG President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speaker 2</td>\n",
       "      <td>Uh, yes, uh, thank you, Jeroen. Well, uh, comm...</td>\n",
       "      <td>2015-02-24 00:00:00</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>michael noonan</td>\n",
       "      <td>Michael Noonan.</td>\n",
       "      <td>2015-02-24 00:00:00</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speaker 2</td>\n",
       "      <td>Uh, it is therefore regrettable that, uh- … th...</td>\n",
       "      <td>2015-02-24 00:00:00</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pierre moscovici</td>\n",
       "      <td>Um, okay colleagues. Um, in general I would sa...</td>\n",
       "      <td>2015-02-24 00:00:00</td>\n",
       "      <td>European Commission</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               speaker                                             speech  \\\n",
       "0  jeroen dijsselbloem  … of your responses or questions. And can I fi...   \n",
       "1            speaker 2  Uh, yes, uh, thank you, Jeroen. Well, uh, comm...   \n",
       "2       michael noonan                                    Michael Noonan.   \n",
       "3            speaker 2  Uh, it is therefore regrettable that, uh- … th...   \n",
       "4     pierre moscovici  Um, okay colleagues. Um, in general I would sa...   \n",
       "\n",
       "                  date               entity  \n",
       "0  2015-02-24 00:00:00         EG President  \n",
       "1  2015-02-24 00:00:00         Unidentified  \n",
       "2  2015-02-24 00:00:00              Ireland  \n",
       "3  2015-02-24 00:00:00         Unidentified  \n",
       "4  2015-02-24 00:00:00  European Commission  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squeezed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b02b02d-79ed-49ab-9dc3-2a7f21cdec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1489 original speech entries, but after \"squeezing\" there are 736 speeches.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {df.speech.size} original speech entries, but after \"squeezing\" there are {df_squeezed.speech.size} speeches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae279cbe-ed0f-4671-adc2-94209d8456a0",
   "metadata": {},
   "source": [
    "### spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5922ffeb-6f93-4a31-8678-87e904562af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58e9e933-307e-44a5-8fe5-bb7fa688f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_token(token):\n",
    "    return token.pos_ in {'ADJ', 'ADV', 'NOUN', 'PROPN', 'VERB'}\\\n",
    "        and not token.is_stop\\\n",
    "        and not token.lower_ in stopwords['names']\\\n",
    "        and not token.lower_ in stopwords['disfluency']\\\n",
    "        and not token.lemma_ in stopwords['courtesy']\\\n",
    "        and len(token.lemma_) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c01f56a8-19a0-453f-a91a-48ba0a42e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df_squeezed.speech.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f27a3e16-33b0-4c2c-9671-425060c83ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "446c1889-a345-42be-ba2b-b10990694a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after tokenization: 108345\n"
     ]
    }
   ],
   "source": [
    "print(f'Tokens after tokenization: {len(tokenized_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6205baa2-ebac-4e74-be7d-401f26d2d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [token.lemma_.lower() for token in tokenized_text if filter_token(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2251254b-3bb7-41ba-adc6-2045e5e6a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply collocations\n",
    "words = apply_bigram_colloc(apply_trigram_colloc(' '.join(words), trigram_colloc), bigram_colloc).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8902cb43-39a5-4880-aa0f-ae2c0f1bd725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after filtering on POS, removing stopwords and punctuation, and joining collocations: 28766\n"
     ]
    }
   ],
   "source": [
    "print(f'Tokens after filtering on POS, removing stopwords and punctuation, and joining collocations: {len(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8469549-abde-4075-a950-81a902e329d7",
   "metadata": {},
   "source": [
    "## Communiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ad6d618-50c8-4339-89b2-8814c9b14270",
   "metadata": {},
   "outputs": [],
   "source": [
    "communiques = pd.read_csv('../data/communiques/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a80ff01-ecba-46e0-b282-2a5f5166b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-12</td>\n",
       "      <td>Remarks by Jeroen Dijsselbloem at the press co...</td>\n",
       "      <td>Good evening. Today, as you well know, we had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-16</td>\n",
       "      <td>Remarks by Jeroen Dijsselbloem at the press co...</td>\n",
       "      <td>Good evening everyone and thanks for joining t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>Eurogroup statement on Greece</td>\n",
       "      <td>The Eurogroup reiterates its appreciation for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>Remarks by Jeroen Dijsselbloem at the press co...</td>\n",
       "      <td>Good evening and welcome to this press confere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>Eurogroup statement on Greece</td>\n",
       "      <td>The Eurogroup today discussed the first list o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2015-02-12  Remarks by Jeroen Dijsselbloem at the press co...   \n",
       "1  2015-02-16  Remarks by Jeroen Dijsselbloem at the press co...   \n",
       "2  2015-02-20                      Eurogroup statement on Greece   \n",
       "3  2015-02-20  Remarks by Jeroen Dijsselbloem at the press co...   \n",
       "4  2015-02-24                      Eurogroup statement on Greece   \n",
       "\n",
       "                                               story  \n",
       "0  Good evening. Today, as you well know, we had ...  \n",
       "1  Good evening everyone and thanks for joining t...  \n",
       "2  The Eurogroup reiterates its appreciation for ...  \n",
       "3  Good evening and welcome to this press confere...  \n",
       "4  The Eurogroup today discussed the first list o...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communiques.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82827437-96ba-4de8-8e93-e1763108b0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 press release.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {communiques.title.size} press release.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a3c15-6d2a-437a-8e90-67301394f0fb",
   "metadata": {},
   "source": [
    "### spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31975de3-b89a-401e-94f9-0a913ae5551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_token(token):\n",
    "    return token.pos_ in {'ADJ', 'ADV', 'NOUN', 'PROPN', 'VERB'}\\\n",
    "        and not token.is_stop\\\n",
    "        and len(token.lemma_) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7dc2b21-c66a-4c2a-a654-c601d231bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(communiques.story.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d63626cc-7333-4a64-a339-ddec02b19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0a07576-44ae-4505-9523-e230c92bed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after tokenization: 9574\n"
     ]
    }
   ],
   "source": [
    "print(f'Tokens after tokenization: {len(tokenized_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fec2c198-5f0f-4797-8088-f5eecfddd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [token.lemma_.lower() for token in tokenized_text if filter_token(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6bef478-585e-4ef5-98f0-e876e108f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply collocations\n",
    "words = apply_bigram_colloc(apply_trigram_colloc(' '.join(words), trigram_colloc), bigram_colloc).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08e2710e-308b-404f-bee8-66184e932130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after filtering on POS, removing stopwords and punctuation, and joining collocations: 3649\n"
     ]
    }
   ],
   "source": [
    "print(f'Tokens after filtering on POS, removing stopwords and punctuation, and joining collocations: {len(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93abbc7-105d-4ae2-be36-06ba5ca20936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
